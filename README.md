# Data-Entry-Job-Automation

ğŸš€ **Project: Automating Real Estate Data Entry Using Web Scraping** ğŸš€

I recently worked on a project that tackled a common task faced in data entry jobs: transferring data from one format to another. The task I focused on was gathering real estate data from a real estate platform, specifically Zillow, and automating the data entry process into a Google Spreadsheet.

Hereâ€™s a quick rundown of how I solved the problem:

ğŸ” **Challenge:**  
A client needed a list of rental properties in San Francisco with specific criteria (up to $3,000/month and at least one bedroom). The challenge was to efficiently gather and organize the data in a way that would save both time and effort while ensuring accuracy.

ğŸ’» **Solution:**
1. **Web Scraping with Beautiful Soup:**  
   First, I wrote a Python script using Beautiful Soup to scrape real estate data from a custom Zillow clone (to avoid website changes that could impact the project). The fields scraped included the price, address, and a link to each listing.

2. **Automating Data Entry with Selenium:**  
   Once the data was scraped, I used Selenium to automatically fill out a Google Form with the gathered details (price, address, and URL) for each property.

3. **Creating a Spreadsheet:**  
   Finally, after form submissions, I linked the responses to a Google Sheet, making it easier for my client to filter through and decide which property to visit.

ğŸ’¡ **Key Takeaway:**  
This project was an excellent demonstration of how Python, Beautiful Soup, and Selenium can be used to automate tedious tasks, freeing up time for more important work. It's also a great example of how web scraping can solve real-world problems and improve efficiency.



#Python #WebScraping #Automation #DataEntry #BeautifulSoup #Selenium #CapstoneProject #TechSolutions #GoogleSheets #Programming #RealEstate #DataScience #MachineLearning #PythonProjects
